{"title":"Setting on the Path of Deep Learning with fastai, lesson 1","markdown":{"yaml":{"title":"Setting on the Path of Deep Learning with fastai, lesson 1","description":"first foray into deep learning using fastai online course and book","date":"2025-07-02","categories":["deep-learning","fastai","lessons","python","kaggle"],"draft":true},"containsRefs":false,"markdown":"\n\n::: center-text\nLike many who have come before , I'm starting on the path of deep learning with [fastai] and their brilliant freely available [course] and companion book. One of their first recommendations, other than learning how to learn, is to start a blog. Why? Because there's no learning like reflection and teaching. Yes, it seems to run counter to the experience many of us had in school - focusing on rote memorization and regurgitation.[^1]\\\n\nThe long and short of it: the best way to learn, is to do. [^2] So here we go.\n\n\\\nStarted with the lesson 1 notebook on [Kaggle], walked through the lesson, then copied it to build my own first classifier!\\\nNow, let's just state up front: it's not very good. The intent was to build a classifier for various species of poisonous mushroom. The problem is, many of the them look alike; so much so that the model thought it had nearly 100% accuracy on exactly the wrong species. For example, when asks to classify a fool's funnel, the model thought it was almost exactly like the death cap. They are two different species; clearly more training or tuning is required.\n\nInitially, I used 3 different species, but it created more confusion for the model than desired. The current iteration uses only 2 species, and the model executed over 20 iterations or epochs. The results were far better this time around.\\\n\n| **epoch** | **train_loss** | **valid_loss** | **error_rate** | **time** |\n|----------:|---------------:|---------------:|---------------:|---------:|\n|         0 |       0.318933 |       0.268419 |       0.101449 |    00:35 |\n|         1 |       0.236353 |       0.250364 |       0.072464 |    00:35 |\n|         2 |       0.180358 |       0.265974 |       0.086957 |    00:35 |\n|         3 |       0.149265 |       0.309172 |       0.072464 |    00:35 |\n|         4 |       0.118095 |       0.332653 |       0.057971 |    00:35 |\n|         5 |       0.094017 |       0.361594 |       0.057971 |    00:34 |\n|         6 |       0.075535 |       0.383202 |       0.072464 |    00:35 |\n|         7 |       0.060396 |       0.364924 |       0.086957 |    00:35 |\n|         8 |       0.051182 |       0.367088 |       0.086957 |    00:35 |\n|         9 |       0.045632 |       0.347216 |       0.086957 |    00:46 |\n|        10 |       0.041189 |       0.267905 |       0.086957 |    00:36 |\n|        11 |       0.034534 |       0.226798 |       0.072464 |    00:35 |\n|        12 |       0.029563 |       0.230915 |       0.057971 |    00:35 |\n|        13 |       0.027720 |       0.257353 |       0.043478 |    00:35 |\n|        14 |       0.023939 |       0.278298 |       0.072464 |    00:36 |\n|        15 |       0.021712 |       0.277783 |       0.072464 |    00:34 |\n|        16 |       0.018345 |       0.273075 |       0.072464 |    00:34 |\n|        17 |       0.016007 |       0.267906 |       0.072464 |    00:35 |\n|        18 |       0.013814 |       0.263237 |       0.072464 |    00:34 |\n|        19 |       0.013254 |       0.266309 |       0.057971 |    00:35 |\n\nThe training loss converges to just above 0, with the error_rate following suite. The valid_loss settles on 0.26, which indicates the model is a bit loss-y, so to speak.\\\n\nThe model maintains a 100% probability when identifying death cap mushrooms:\n\n::: {.column-margin}\n![](/posts/images/deathcap.jpg)\n:::\n\n```\nThis is a: death cap.\nProbability it's a death cap: 1.0000\n```\n\n\\\nNot so accurate when classifying fly agaric:\\\n\n::: {.column-margin} \n![](/posts/images/agaric.jpg)\n::: \n\n```         \nThis is a: fly agaric.\nProbability it's a fly agaric: 0.0031\n```\n\nThe probability of accuracy is tiny, but still correct.\\\n\\\nAt this point, it's unclear what steps to take to improve the result for fly agaric classification. It could be there aren't enough distinctions between the samples in the data set, rendering them too similar for the model to tell the difference. As this is the beginning, refining and training models and analysing output can only get better.\\\n\\\nHead on over to [Kaggle] to interact the fully-functional notebook.\\\n\\\nThanks for reading. Onward and upward.\n:::\n\n[^1]: Lots to discuss, reveal explore on the topic of learning to learn. Start here: [Ted Talk] and here: [Coursera]\n\n[^2]: Personal reflections on learning, trying vs. doing \\[\\[INSERT LINK to BLOG\\]\\]\n\n  [fastai]: https://www.fast.ai/\n  [course]: https://course.fast.ai/\n  [Kaggle]: https://www.kaggle.com/code/ksangster/is-it-death-creating-a-model-from-your-own-data \"Kaggle notebook for first fastai lesson\"\n  [Ted Talk]: https://www.youtube.com/watch?v=O96fE1E-rf8\n  [Coursera]: https://www.coursera.org/learn/learning-how-to-learn","srcMarkdownNoYaml":"\n\n::: center-text\nLike many who have come before , I'm starting on the path of deep learning with [fastai] and their brilliant freely available [course] and companion book. One of their first recommendations, other than learning how to learn, is to start a blog. Why? Because there's no learning like reflection and teaching. Yes, it seems to run counter to the experience many of us had in school - focusing on rote memorization and regurgitation.[^1]\\\n\nThe long and short of it: the best way to learn, is to do. [^2] So here we go.\n\n\\\nStarted with the lesson 1 notebook on [Kaggle], walked through the lesson, then copied it to build my own first classifier!\\\nNow, let's just state up front: it's not very good. The intent was to build a classifier for various species of poisonous mushroom. The problem is, many of the them look alike; so much so that the model thought it had nearly 100% accuracy on exactly the wrong species. For example, when asks to classify a fool's funnel, the model thought it was almost exactly like the death cap. They are two different species; clearly more training or tuning is required.\n\nInitially, I used 3 different species, but it created more confusion for the model than desired. The current iteration uses only 2 species, and the model executed over 20 iterations or epochs. The results were far better this time around.\\\n\n| **epoch** | **train_loss** | **valid_loss** | **error_rate** | **time** |\n|----------:|---------------:|---------------:|---------------:|---------:|\n|         0 |       0.318933 |       0.268419 |       0.101449 |    00:35 |\n|         1 |       0.236353 |       0.250364 |       0.072464 |    00:35 |\n|         2 |       0.180358 |       0.265974 |       0.086957 |    00:35 |\n|         3 |       0.149265 |       0.309172 |       0.072464 |    00:35 |\n|         4 |       0.118095 |       0.332653 |       0.057971 |    00:35 |\n|         5 |       0.094017 |       0.361594 |       0.057971 |    00:34 |\n|         6 |       0.075535 |       0.383202 |       0.072464 |    00:35 |\n|         7 |       0.060396 |       0.364924 |       0.086957 |    00:35 |\n|         8 |       0.051182 |       0.367088 |       0.086957 |    00:35 |\n|         9 |       0.045632 |       0.347216 |       0.086957 |    00:46 |\n|        10 |       0.041189 |       0.267905 |       0.086957 |    00:36 |\n|        11 |       0.034534 |       0.226798 |       0.072464 |    00:35 |\n|        12 |       0.029563 |       0.230915 |       0.057971 |    00:35 |\n|        13 |       0.027720 |       0.257353 |       0.043478 |    00:35 |\n|        14 |       0.023939 |       0.278298 |       0.072464 |    00:36 |\n|        15 |       0.021712 |       0.277783 |       0.072464 |    00:34 |\n|        16 |       0.018345 |       0.273075 |       0.072464 |    00:34 |\n|        17 |       0.016007 |       0.267906 |       0.072464 |    00:35 |\n|        18 |       0.013814 |       0.263237 |       0.072464 |    00:34 |\n|        19 |       0.013254 |       0.266309 |       0.057971 |    00:35 |\n\nThe training loss converges to just above 0, with the error_rate following suite. The valid_loss settles on 0.26, which indicates the model is a bit loss-y, so to speak.\\\n\nThe model maintains a 100% probability when identifying death cap mushrooms:\n\n::: {.column-margin}\n![](/posts/images/deathcap.jpg)\n:::\n\n```\nThis is a: death cap.\nProbability it's a death cap: 1.0000\n```\n\n\\\nNot so accurate when classifying fly agaric:\\\n\n::: {.column-margin} \n![](/posts/images/agaric.jpg)\n::: \n\n```         \nThis is a: fly agaric.\nProbability it's a fly agaric: 0.0031\n```\n\nThe probability of accuracy is tiny, but still correct.\\\n\\\nAt this point, it's unclear what steps to take to improve the result for fly agaric classification. It could be there aren't enough distinctions between the samples in the data set, rendering them too similar for the model to tell the difference. As this is the beginning, refining and training models and analysing output can only get better.\\\n\\\nHead on over to [Kaggle] to interact the fully-functional notebook.\\\n\\\nThanks for reading. Onward and upward.\n:::\n\n[^1]: Lots to discuss, reveal explore on the topic of learning to learn. Start here: [Ted Talk] and here: [Coursera]\n\n[^2]: Personal reflections on learning, trying vs. doing \\[\\[INSERT LINK to BLOG\\]\\]\n\n  [fastai]: https://www.fast.ai/\n  [course]: https://course.fast.ai/\n  [Kaggle]: https://www.kaggle.com/code/ksangster/is-it-death-creating-a-model-from-your-own-data \"Kaggle notebook for first fastai lesson\"\n  [Ted Talk]: https://www.youtube.com/watch?v=O96fE1E-rf8\n  [Coursera]: https://www.coursera.org/learn/learning-how-to-learn"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":false,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":["spacelab","cosmo","brand"],"title-block-banner":true,"citation":false,"title":"Setting on the Path of Deep Learning with fastai, lesson 1","description":"first foray into deep learning using fastai online course and book","date":"2025-07-02","categories":["deep-learning","fastai","lessons","python","kaggle"],"draft":true},"extensions":{"book":{"multiFile":true}}}},"draft":true,"projectFormats":["html"]}